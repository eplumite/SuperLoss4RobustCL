{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Generate_noise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcKyN0eyg0V7"
      },
      "source": [
        "# Symmetric noise -- KITTY MDE -- DEPTH ESTIMATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z2ld5DZg0V_"
      },
      "source": [
        "from os import listdir, makedirs\n",
        "from os.path import isfile, join, exists\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "\n",
        "def spoil(init, nu):\n",
        "    spoiled = np.arange(len(init))\n",
        "    idx_shuffle = np.arange(len(init))\n",
        "    n_shuffle = int(nu * len(init))\n",
        "    rng = np.random.default_rng()\n",
        "    rng.shuffle(idx_shuffle)\n",
        "    idx_shuffle = idx_shuffle[:n_shuffle] \n",
        "    idx_to_shuffle = np.sort(idx_shuffle)\n",
        "    count = 0\n",
        "    for i in range(len(init)):\n",
        "        if (count < n_shuffle) and (i == idx_to_shuffle[count]):\n",
        "            spoiled[i] = idx_shuffle[count]\n",
        "            count += 1\n",
        "        print(i, ' --> ', spoiled[i])\n",
        "    #print(spoiled)\n",
        "    return np.array(spoiled)\n",
        "\n",
        "def generate_noise_NOCLASSES(inpath, nu, outpath_prefix='_noise_'): #symmetric noise\n",
        "    # generate new path\n",
        "    split_path = inpath.split('/')\n",
        "    inpath_prefix = split_path[0]\n",
        "    inpath_suffix = inpath[len(split_path[0]):] \n",
        "    newpath = inpath_prefix + outpath_prefix + str(nu) + inpath_suffix\n",
        "    if not exists(newpath):\n",
        "        makedirs(newpath)\n",
        "        print('Data with noise_coeff=', nu, 'will be placed in the folder:')\n",
        "        print(newpath)\n",
        "    # generate new labels\n",
        "    initial_labels = [f for f in listdir(inpath) if isfile(join(inpath, f))]\n",
        "    noisy_idx = spoil(initial_labels, nu)\n",
        "    # save new data\n",
        "    for i in range(len(initial_labels)):\n",
        "        shutil.copy(inpath + initial_labels[i],\n",
        "                    newpath + initial_labels[noisy_idx[i]])\n",
        "    print('Data successfully saved!\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShQ_rvSPg0WA"
      },
      "source": [
        "# nu is the percentage of noisy masks\n",
        "for nu in [0.4, 0.8]:\n",
        "    inpath = 'dataset_kitti_MDE/train/masks/'   #<---- сюда пишем путь к папке, где лежат маски для Train\n",
        "    generate_noise_NOCLASSES(inpath, nu)  \n",
        "    inpath = 'dataset_kitti_MDE/val/masks/'     #<---- сюда пишем путь к папке, где лежат маски для Test\n",
        "    generate_noise_NOCLASSES(inpath, nu)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sAhG9Reg0WA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL6M2GfWg0WA"
      },
      "source": [
        "# Symmetric noise WITH CLASSES -- KITTY SEGMENTATION DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoNA4PF5g0WB"
      },
      "source": [
        "import os\n",
        "from os import listdir, makedirs\n",
        "from os.path import isfile, join, exists\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "\n",
        "def find_names_in_fold(prefix):\n",
        "    class_names = np.sort(os.listdir(prefix))\n",
        "    if '.DS_Store' in class_names:\n",
        "        place_DS_Store = np.where(class_names == '.DS_Store')\n",
        "        class_names = np.delete(class_names, place_DS_Store[0][0])\n",
        "    list_names = np.sort(os.listdir(prefix + class_names[0])).tolist()\n",
        "    for i, x in enumerate(list_names):\n",
        "        list_names[i] = os.path.join(class_names[0],x)\n",
        "    for i in class_names[1:]:\n",
        "        list_names_onefold = np.sort(os.listdir(prefix + i)).tolist()\n",
        "        for j, x in enumerate(list_names_onefold):\n",
        "            list_names_onefold[j] = os.path.join(i, x)\n",
        "        list_names.extend(list_names_onefold)\n",
        "    return list_names\n",
        "\n",
        "def spoil(init, nu):\n",
        "    spoiled = np.arange(len(init))\n",
        "    idx_shuffle = np.arange(len(init))\n",
        "    n_shuffle = int(nu * len(init))\n",
        "    rng = np.random.default_rng()\n",
        "    rng.shuffle(idx_shuffle)\n",
        "    idx_shuffle = idx_shuffle[:n_shuffle] \n",
        "    idx_to_shuffle = np.sort(idx_shuffle)\n",
        "    count = 0\n",
        "    for i in range(len(init)):\n",
        "        if (count < n_shuffle) and (i == idx_to_shuffle[count]):\n",
        "            spoiled[i] = idx_shuffle[count]\n",
        "            count += 1\n",
        "        print(i, ' --> ', spoiled[i])\n",
        "    #print(spoiled)\n",
        "    return np.array(spoiled)\n",
        "\n",
        "def generate_noise(inpath, nu, outpath_prefix='_noise_'): #symmetric noise\n",
        "    # generate new path\n",
        "    split_path = inpath.split('/')\n",
        "    inpath_prefix = split_path[0]\n",
        "    inpath_suffix = inpath[len(split_path[0]):] \n",
        "    newpath = inpath_prefix + outpath_prefix + str(nu) + inpath_suffix\n",
        "    if not exists(newpath):\n",
        "        makedirs(newpath)\n",
        "        print('Data with noise_coeff=', nu, 'will be placed in the folder:')\n",
        "        print(newpath)\n",
        "    # form initial labels and new folders\n",
        "    class_names = np.sort(listdir(inpath))\n",
        "    for class_name in class_names:\n",
        "        #print(newpath + class_name)\n",
        "        if not exists(newpath + class_name):\n",
        "            makedirs(newpath + class_name)\n",
        "            print(newpath + class_name)\n",
        "            print('Created new path', newpath + class_name)\n",
        "            #print(newpath)\n",
        "    #print(newpath, class_names)\n",
        "    # generate new labels\n",
        "    initial_labels = find_names_in_fold(inpath) #[f for f in listdir(inpath) if isfile(join(inpath, f))]\n",
        "    print(initial_labels)\n",
        "    noisy_idx = spoil(initial_labels, nu)\n",
        "    ## save new data\n",
        "    for i in range(len(initial_labels)):\n",
        "        shutil.copy(inpath + initial_labels[i],\n",
        "                    newpath + initial_labels[noisy_idx[i]])\n",
        "    print('Data successfully saved!\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykz3y94jg0WB"
      },
      "source": [
        "# nu is the percentage of noisy masks\n",
        "for nu in [0.02, 0.05, 0.1, 0.2, 0.3, 0.4]:\n",
        "    inpath = 'train_val_dataset/train/masks/' #<---- сюда пишем путь к папке, где лежат маски для MDE Train\n",
        "    generate_noise(inpath, nu)  \n",
        "    inpath = 'train_val_dataset/val/masks/'   #<---- сюда пишем путь к папке, где лежат маски для MDE Test\n",
        "    generate_noise(inpath, nu)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uxPHeBBg0WB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IhBODakg0WC"
      },
      "source": [
        "# Noise in IMAGE BOUDARY NO CLASSES -- LIPS DATASET "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TSyQ4Xwg0WC",
        "outputId": "7d7bdcb0-d63e-4a33-95fd-5cf3d2434c14"
      },
      "source": [
        "pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.5.1.48)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from opencv-python) (1.18.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SaXs1lsg0WC"
      },
      "source": [
        "import random \n",
        "import cv2 \n",
        "\n",
        "from os import listdir, makedirs\n",
        "from os.path import isfile, join, exists\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "\n",
        "def binarize(rocket, boudary):\n",
        "    copy = np.array(rocket).copy()\n",
        "    new_rocket = copy[:,:]\n",
        "    \n",
        "    new_rocket[new_rocket > boudary] = 255\n",
        "    new_rocket[new_rocket <= boudary] = 0\n",
        "    return new_rocket\n",
        "\n",
        "def add_noise2lips(img): \n",
        "    print(img.shape)\n",
        "    row , col, _ = img.shape \n",
        "    \n",
        "    pts = []\n",
        "    number_of_pixels = random.randint(30, 200) \n",
        "    i = 0\n",
        "    while(i == 0): \n",
        "        y_coord=random.randint(0, row - 1) \n",
        "        x_coord=random.randint(0, col - 1)\n",
        "        if (sum(img[y_coord][x_coord]) > 0):\n",
        "            pts.append([x_coord, y_coord])\n",
        "            i+=1\n",
        "    while(i < number_of_pixels or sum(img[y_coord][x_coord]) > 0):\n",
        "        y_coord += random.randint(-2, 2) \n",
        "        x_coord += random.randint(-2, 2)\n",
        "        pts.append([x_coord, y_coord])\n",
        "        i+=1\n",
        "    print(pts)\n",
        "    pts = np.array(pts)\n",
        "    pts = pts.reshape((-1, 1, 2))  \n",
        "    #print('here ', img[pts[0, 0, 0], pts[0, 0, 1]])\n",
        "    color = (34, 255, 14)\n",
        "    print(color)\n",
        "    img = cv2.polylines(img, [pts], True, color, 10)\n",
        "    return img \n",
        "\n",
        "def spoil_lip(in_filename, out_filename):\n",
        "    img = cv2.imread(in_filename)\n",
        "    #img = binarize(img, 1)\n",
        "    img = add_noise2lips(img)\n",
        "    cv2.imwrite(out_filename, img) \n",
        "    \n",
        "def pick_lips(init, nu):\n",
        "    spoiled = np.arange(len(init))\n",
        "    initial = np.arange(len(init))\n",
        "    idx_shuffle = np.arange(len(init))\n",
        "    n_shuffle = int(nu * len(init))\n",
        "    rng = np.random.default_rng()\n",
        "    rng.shuffle(idx_shuffle)\n",
        "    idx_shuffle = idx_shuffle[:n_shuffle] \n",
        "    idx_to_shuffle = np.sort(idx_shuffle)\n",
        "    count = 0\n",
        "    for i in range(len(init)):\n",
        "        if (count < n_shuffle) and (i == idx_to_shuffle[count]):\n",
        "            spoiled[i] = -1\n",
        "            count += 1\n",
        "        print(i, ' --> ', spoiled[i])\n",
        "    #print(spoiled)\n",
        "    return np.array(spoiled)\n",
        "    \n",
        "def generate_noise_lips_NOCLASSES(inpath, nu, outpath_prefix='_noise_'): #symmetric noise\n",
        "    # generate new path\n",
        "    split_path = inpath.split('/')\n",
        "    inpath_prefix = split_path[0]\n",
        "    inpath_suffix = inpath[len(split_path[0]):] \n",
        "    newpath = inpath_prefix + outpath_prefix + str(nu) + inpath_suffix\n",
        "    if not exists(newpath):\n",
        "        makedirs(newpath)\n",
        "        print('Data with noise_coeff=', nu, 'will be placed in the folder:')\n",
        "        print(newpath)\n",
        "    # generate new labels\n",
        "    initial_labels = [f for f in listdir(inpath) if isfile(join(inpath, f))]\n",
        "    noisy_idx = pick_lips(initial_labels, nu)\n",
        "    # save new data\n",
        "    for i in range(len(initial_labels)):\n",
        "        if noisy_idx[i] == -1:\n",
        "            spoil_lip(inpath + initial_labels[i], newpath + initial_labels[i])\n",
        "        else:\n",
        "            shutil.copy(inpath + initial_labels[i], newpath + initial_labels[i])\n",
        "    print('Data successfully saved!\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH5LVTq-g0WF"
      },
      "source": [
        "# nu is the percentage of noisy masks\n",
        "for nu in [0.02, 0.05, 0.1, 0.2, 0.3, 0.4]:\n",
        "    inpath = 'initial_lips_masks_folder/'      #<---- сюда пишем путь к папке, где лежат маски для губ\n",
        "    generate_noise_lips_NOCLASSES(inpath, nu)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYvCTyWcg-i5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LRYT5hSg-o0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm613yhIhCg1"
      },
      "source": [
        "# Noise in IMAGE BOUDARY NO CLASSES -- TikTok Dansers DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3xQdvpOhIvr"
      },
      "source": [
        "pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcyAr0g_hYV9"
      },
      "source": [
        "import random \n",
        "import cv2 \n",
        "\n",
        "from os import listdir, makedirs\n",
        "from os.path import isfile, join, exists\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "\n",
        "def binarize(rocket, boudary):\n",
        "    copy = np.array(rocket).copy()\n",
        "    new_rocket = copy[:,:]\n",
        "    \n",
        "    new_rocket[new_rocket > boudary] = 255\n",
        "    new_rocket[new_rocket <= boudary] = 0\n",
        "    return new_rocket\n",
        "\n",
        "def add_noise2lips(img): \n",
        "    print(img.shape)\n",
        "    row , col, _ = img.shape \n",
        "    \n",
        "    pts = []\n",
        "    number_of_pixels = random.randint(30, 800) \n",
        "    i = 0\n",
        "    while(i == 0): \n",
        "        y_coord=random.randint(0, row - 1) \n",
        "        x_coord=random.randint(0, col - 1)\n",
        "        if (sum(img[y_coord][x_coord]) > 0):\n",
        "            pts.append([x_coord, y_coord])\n",
        "            i+=1\n",
        "    while((i < number_of_pixels or sum(img[y_coord][x_coord]) > 0) and 3 < y_coord < row-3 and 3 < x_coord < col-3):\n",
        "        y_coord += random.randint(-2, 2) \n",
        "        x_coord += random.randint(-2, 2)\n",
        "        pts.append([x_coord, y_coord])\n",
        "        i+=1\n",
        "    #print(pts)\n",
        "    pts = np.array(pts)\n",
        "    pts = pts.reshape((-1, 1, 2))  \n",
        "    #print('here ', img[pts[0, 0, 0], pts[0, 0, 1]])\n",
        "    color = (0, 0, 0)\n",
        "    #print(color)\n",
        "    img = cv2.polylines(img, [pts], True, color, 15)\n",
        "    \n",
        "    pts = []\n",
        "    number_of_pixels = random.randint(30, 800) \n",
        "    i = 0\n",
        "    while(i == 0): \n",
        "        y_coord=random.randint(0, row - 1) \n",
        "        x_coord=random.randint(0, col - 1)\n",
        "        if (sum(img[y_coord][x_coord]) == 0):\n",
        "            pts.append([x_coord, y_coord])\n",
        "            i+=1\n",
        "    while((i < number_of_pixels or sum(img[y_coord][x_coord]) == 0) and 3 < y_coord < row-3 and 3 < x_coord < col-3):\n",
        "        y_coord += random.randint(-2, 2) \n",
        "        x_coord += random.randint(-2, 2)\n",
        "        pts.append([x_coord, y_coord])\n",
        "        i+=1\n",
        "    #print(pts)\n",
        "    pts = np.array(pts)\n",
        "    pts = pts.reshape((-1, 1, 2))  \n",
        "    #print('here ', img[pts[0, 0, 0], pts[0, 0, 1]])\n",
        "    color = (255, 255, 255)\n",
        "    #print(color)\n",
        "    img = cv2.polylines(img, [pts], True, color, 15)\n",
        "    \n",
        "    return img \n",
        "\n",
        "def spoil_lip(in_filename, out_filename):\n",
        "    img = cv2.imread(in_filename)\n",
        "    #img = binarize(img, 1)\n",
        "    repeat = random.randint(1, 10)\n",
        "    print(repeat)\n",
        "    for _ in range(repeat):\n",
        "        img = add_noise2lips(img)\n",
        "    cv2.imwrite(out_filename, img) \n",
        "    \n",
        "def pick_lips(init, nu):\n",
        "    spoiled = np.arange(len(init))\n",
        "    initial = np.arange(len(init))\n",
        "    idx_shuffle = np.arange(len(init))\n",
        "    n_shuffle = int(nu * len(init))\n",
        "    rng = np.random.default_rng()\n",
        "    rng.shuffle(idx_shuffle)\n",
        "    idx_shuffle = idx_shuffle[:n_shuffle] \n",
        "    idx_to_shuffle = np.sort(idx_shuffle)\n",
        "    count = 0\n",
        "    for i in range(len(init)):\n",
        "        if (count < n_shuffle) and (i == idx_to_shuffle[count]):\n",
        "            spoiled[i] = -1\n",
        "            count += 1\n",
        "        #print(i, ' --> ', spoiled[i])\n",
        "    #print(spoiled)\n",
        "    return np.array(spoiled)\n",
        "    \n",
        "def generate_noise_lips_NOCLASSES(inpath, nu, outpath_prefix='_noise_'): #symmetric noise\n",
        "    # generate new path\n",
        "    split_path = inpath.split('/')\n",
        "    inpath_prefix = split_path[0]\n",
        "    inpath_suffix = inpath[len(split_path[0]):] \n",
        "    newpath = inpath_prefix + outpath_prefix + str(nu) + inpath_suffix\n",
        "    if not exists(newpath):\n",
        "        makedirs(newpath)\n",
        "        print('Data with noise_coeff=', nu, 'will be placed in the folder:')\n",
        "        print(newpath)\n",
        "    # generate new labels\n",
        "    initial_labels = [f for f in listdir(inpath) if isfile(join(inpath, f))]\n",
        "    noisy_idx = pick_lips(initial_labels, nu)\n",
        "    # save new data\n",
        "    for i in range(len(initial_labels)):\n",
        "        if noisy_idx[i] == -1:\n",
        "            print(inpath + initial_labels[i])\n",
        "            spoil_lip(inpath + initial_labels[i], newpath + initial_labels[i])\n",
        "        else:\n",
        "            shutil.copy(inpath + initial_labels[i], newpath + initial_labels[i])\n",
        "    print('Data successfully saved!\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGqUfnvShY0K"
      },
      "source": [
        "# nu is the percentage of noisy masks\n",
        "for nu in [0.4, 0.6, 0.8]:\n",
        "    inpath = 'dataset_people/train/masks/' #<---- сюда пишем путь к папке, где лежат маски для губ\n",
        "    generate_noise_lips_NOCLASSES(inpath, nu)     \n",
        "    inpath = 'dataset_people/val/masks/' #<---- сюда пишем путь к папке, где лежат маски для губ\n",
        "    generate_noise_lips_NOCLASSES(inpath, nu)     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc473kPehY2l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPCWoWeYhhgT"
      },
      "source": [
        "# Noise in IMAGE BOUDARY NO CLASSES -- Lungs DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGbKkGIHhmxz"
      },
      "source": [
        "pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdmMPIq9hoW4"
      },
      "source": [
        "import random \n",
        "import cv2 \n",
        "\n",
        "from os import listdir, makedirs\n",
        "from os.path import isfile, join, exists\n",
        "import shutil\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "\n",
        "def binarize(rocket, boudary):\n",
        "    copy = np.array(rocket).copy()\n",
        "    new_rocket = copy[:,:]\n",
        "    \n",
        "    new_rocket[new_rocket > boudary] = 255\n",
        "    new_rocket[new_rocket <= boudary] = 0\n",
        "    return new_rocket\n",
        "\n",
        "def add_noise2lips(img): \n",
        "    print(img.shape)\n",
        "    row , col, _ = img.shape \n",
        "    \n",
        "    pts = []\n",
        "    number_of_pixels = random.randint(30, 150) \n",
        "    i = 0\n",
        "    while(i == 0): \n",
        "        y_coord=random.randint(0, row - 1) \n",
        "        x_coord=random.randint(0, col - 1)\n",
        "        if (sum(img[y_coord][x_coord]) > 0):\n",
        "            pts.append([x_coord, y_coord])\n",
        "            i+=1\n",
        "    while((i < number_of_pixels or sum(img[y_coord][x_coord]) > 0) and 3 < y_coord < row-3 and 3 < x_coord < col-3):\n",
        "        y_coord += random.randint(-2, 2) \n",
        "        x_coord += random.randint(-2, 2)\n",
        "        pts.append([x_coord, y_coord])\n",
        "        i+=1\n",
        "    #print(pts)\n",
        "    pts = np.array(pts)\n",
        "    pts = pts.reshape((-1, 1, 2))  \n",
        "    #print('here ', img[pts[0, 0, 0], pts[0, 0, 1]])\n",
        "    color = (0, 0, 0)\n",
        "    #print(color)\n",
        "    thikness = random.randint(5, 15)\n",
        "    img = cv2.polylines(img, [pts], True, color, thikness)\n",
        "    \n",
        "    pts = []\n",
        "    number_of_pixels = random.randint(30, 150) \n",
        "    i = 0\n",
        "    while(i == 0): \n",
        "        y_coord=random.randint(0, row - 1) \n",
        "        x_coord=random.randint(0, col - 1)\n",
        "        if (sum(img[y_coord][x_coord]) == 0):\n",
        "            pts.append([x_coord, y_coord])\n",
        "            i+=1\n",
        "    while((i < number_of_pixels or sum(img[y_coord][x_coord]) == 0) and 3 < y_coord < row-3 and 3 < x_coord < col-3):\n",
        "        y_coord += random.randint(-2, 2) \n",
        "        x_coord += random.randint(-2, 2)\n",
        "        pts.append([x_coord, y_coord])\n",
        "        i+=1\n",
        "    #print(pts)\n",
        "    pts = np.array(pts)\n",
        "    pts = pts.reshape((-1, 1, 2))  \n",
        "    #print('here ', img[pts[0, 0, 0], pts[0, 0, 1]])\n",
        "    color = (255, 255, 255)\n",
        "    #print(color)\n",
        "    thikness = random.randint(5, 15)\n",
        "    img = cv2.polylines(img, [pts], True, color, thikness)\n",
        "    \n",
        "    return img \n",
        "\n",
        "def spoil_lip(in_filename, out_filename):\n",
        "    img = cv2.imread(in_filename)\n",
        "    #img = binarize(img, 1)\n",
        "    repeat = random.randint(1, 10)\n",
        "    print(repeat)\n",
        "    for _ in range(repeat):\n",
        "        img = add_noise2lips(img)\n",
        "    cv2.imwrite(out_filename, img) \n",
        "    \n",
        "def pick_lips(init, nu):\n",
        "    spoiled = np.arange(len(init))\n",
        "    initial = np.arange(len(init))\n",
        "    idx_shuffle = np.arange(len(init))\n",
        "    n_shuffle = int(nu * len(init))\n",
        "    rng = np.random.default_rng()\n",
        "    rng.shuffle(idx_shuffle)\n",
        "    idx_shuffle = idx_shuffle[:n_shuffle] \n",
        "    idx_to_shuffle = np.sort(idx_shuffle)\n",
        "    count = 0\n",
        "    for i in range(len(init)):\n",
        "        if (count < n_shuffle) and (i == idx_to_shuffle[count]):\n",
        "            spoiled[i] = -1\n",
        "            count += 1\n",
        "        #print(i, ' --> ', spoiled[i])\n",
        "    #print(spoiled)\n",
        "    return np.array(spoiled)\n",
        "    \n",
        "def generate_noise_lips_NOCLASSES(inpath, nu, outpath_prefix='_noise_'): #symmetric noise\n",
        "    # generate new path\n",
        "    split_path = inpath.split('/')\n",
        "    inpath_prefix = split_path[0]\n",
        "    inpath_suffix = inpath[len(split_path[0]):] \n",
        "    newpath = inpath_prefix + outpath_prefix + str(nu) + inpath_suffix\n",
        "    if not exists(newpath):\n",
        "        makedirs(newpath)\n",
        "        print('Data with noise_coeff=', nu, 'will be placed in the folder:')\n",
        "        print(newpath)\n",
        "    # generate new labels\n",
        "    initial_labels = [f for f in listdir(inpath) if isfile(join(inpath, f))]\n",
        "    noisy_idx = pick_lips(initial_labels, nu)\n",
        "    # save new data\n",
        "    for i in range(len(initial_labels)):\n",
        "        if noisy_idx[i] == -1:\n",
        "            print(inpath + initial_labels[i])\n",
        "            spoil_lip(inpath + initial_labels[i], newpath + initial_labels[i])\n",
        "        else:\n",
        "            shutil.copy(inpath + initial_labels[i], newpath + initial_labels[i])\n",
        "    print('Data successfully saved!\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doScLPAkhxC2"
      },
      "source": [
        "# nu is the percentage of noisy masks\n",
        "for nu in [0.4, 0.6, 0.8]:\n",
        "    inpath = 'dataset_med/train/masks/'  #<---- сюда пишем путь к папке, где лежат маски для губ\n",
        "    generate_noise_lips_NOCLASSES(inpath, nu)     \n",
        "    inpath = 'dataset_med/val/masks/'    #<---- сюда пишем путь к папке, где лежат маски для губ\n",
        "    generate_noise_lips_NOCLASSES(inpath, nu) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}